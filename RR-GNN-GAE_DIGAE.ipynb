{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsU6JxXrqFF0"
      },
      "source": [
        "2150 edges, 546 nodes, 9014 edges in the line graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk6YipPiKR0p",
        "outputId": "d680741c-d423-4431-c5e2-e937f6050aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.8)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-p1PnKWzKR0p"
      },
      "outputs": [],
      "source": [
        "import autoencoder\n",
        "from autoencoder import VGAE, GAE, EdgeDecoder, DirectedEdgeDecoder, InnerProductDecoder, DirectedInnerProductDecoder\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import copy\n",
        "import torch\n",
        "from torch_geometric.utils.convert import from_networkx\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from scipy.stats import ranksums\n",
        "from torch_geometric.nn import GraphConv, SAGEConv, GATConv, GCNConv\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.transforms import LineGraph, RandomNodeSplit, RandomLinkSplit\n",
        "from torch_geometric import seed_everything\n",
        "\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGTn0NorZWIc"
      },
      "outputs": [],
      "source": [
        "node_rename = {node: id for id, node in enumerate(range(388, 934))}\n",
        "nodefile = 'ChicagoSketch_node.tntp'\n",
        "node = pd.read_csv(nodefile, sep='\\t', usecols=['node', 'X', 'Y'])\n",
        "flowfile = 'ChicagoSketch_flow.tntp'\n",
        "colname = 'Volume '\n",
        "flow = pd.read_csv(flowfile, sep='\\t', usecols=['From ', 'To ', colname])\n",
        "\n",
        "node['node'] = node['node'].map(node_rename)\n",
        "node = node[node['node'].notna()]\n",
        "\n",
        "flow['From '] = flow['From '].map(node_rename)\n",
        "flow['To '] = flow['To '].map(node_rename)\n",
        "flow = flow[(flow['From '].notna()) & (flow['To '].notna())]\n",
        "flow.drop(flow[flow[colname] <= 0].index, inplace=True)\n",
        "flow[colname] = np.log(flow[colname])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "node[['X', 'Y']] = scaler.fit_transform(node[['X', 'Y']].values)\n",
        "# minmax = MinMaxScaler()\n",
        "# flow[[colname]] = minmax.fit_transform(flow[[colname]].values)\n",
        "\n",
        "df = flow.rename(columns={'From ': 's', 'To ': 'r', colname: 'w'})\n",
        "df1 = pd.merge(df, node, how='left', left_on='s', right_on='node')[['s', 'r', 'w', 'X', 'Y']].rename(columns={'X': 'X1', 'Y': 'Y1'})\n",
        "df2 = pd.merge(df1, node, how='left', left_on='r', right_on='node')[['s', 'r', 'w', 'X1', 'Y1', 'X', 'Y']].rename(columns={'X': 'X2', 'Y': 'Y2'})\n",
        "df2['feat'] = df2[['X1', 'Y1', 'X2', 'Y2']].values.tolist()\n",
        "\n",
        "edge_name_to_y = {(s, r): w for s, r, w in df2[['s', 'r', 'w']].values}\n",
        "edge_name_to_x = {(s, r): feat for s, r, feat in df2[['s', 'r', 'feat']].values}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-2gzv5lcQ4R"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "nodefile = 'anaheim_nodes.geojson'\n",
        "nodes = gpd.read_file(nodefile)\n",
        "nodes_df = pd.DataFrame(nodes)\n",
        "nodes_df[['X', 'Y']] = nodes_df['geometry'].astype(str).str.split('(').str[-1].str.split(')').str[0].str.split(' ', expand=True).astype(np.float32)\n",
        "node = nodes_df.rename(columns={'id': 'node'})\n",
        "\n",
        "node_rename = {node: id for id, node in enumerate(range(1, 417))}\n",
        "node['node'] = node['node'].map(node_rename)\n",
        "\n",
        "flowfile = 'Anaheim_flow.tntp'\n",
        "colname = 'Volume '\n",
        "flow = pd.read_csv(flowfile, sep='\\t', usecols=['From ', 'To ', colname])\n",
        "\n",
        "flow['From '] = flow['From '].map(node_rename)\n",
        "flow['To '] = flow['To '].map(node_rename)\n",
        "flow = flow[(flow['From '].notna()) & (flow['To '].notna())]\n",
        "flow.drop(flow[flow[colname] <= 0].index, inplace=True)\n",
        "flow[colname] = np.log(flow[colname])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "node[['X', 'Y']] = scaler.fit_transform(node[['X', 'Y']].values)\n",
        "# minmax = MinMaxScaler()\n",
        "# flow[[colname]] = minmax.fit_transform(flow[[colname]].values)\n",
        "\n",
        "df = flow.rename(columns={'From ': 's', 'To ': 'r', colname: 'w'})\n",
        "df1 = pd.merge(df, node, how='left', left_on='s', right_on='node')[['s', 'r', 'w', 'X', 'Y']].rename(columns={'X': 'X1', 'Y': 'Y1'})\n",
        "df2 = pd.merge(df1, node, how='left', left_on='r', right_on='node')[['s', 'r', 'w', 'X1', 'Y1', 'X', 'Y']].rename(columns={'X': 'X2', 'Y': 'Y2'})\n",
        "df2['feat'] = df2[['X1', 'Y1', 'X2', 'Y2']].values.tolist()\n",
        "\n",
        "edge_name_to_y = {(s, r): w for s, r, w in df2[['s', 'r', 'w']].values}\n",
        "edge_name_to_x = {(s, r): feat for s, r, feat in df2[['s', 'r', 'feat']].values}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wth_R9QvztHJ",
        "outputId": "3140ecf9-86bc-434d-a8a1-96254cf0c3fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oWbSOVtxoTJ",
        "outputId": "776f4f06-1d09-4b69-e2fe-43658f4161bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 858], w=[858], num_nodes=413, x=[416, 2])\n",
            "Data(edge_index=[2, 2214], num_nodes=858, x=[858, 4], y=[858, 1])\n"
          ]
        }
      ],
      "source": [
        "G = nx.from_pandas_edgelist(df2, source='s', target='r', edge_attr='w', create_using=nx.DiGraph())\n",
        "airport = from_networkx(G)\n",
        "airport.x = torch.from_numpy(node[['X', 'Y']].values).to(torch.float32)\n",
        "print(airport)\n",
        "\n",
        "G_line_graph = nx.line_graph(G, create_using=nx.DiGraph())\n",
        "airport_line_graph = from_networkx(G_line_graph)\n",
        "airport_line_graph.x = torch.from_numpy(np.vstack([edge_name_to_x[e] for e in G_line_graph.nodes])).to(torch.float32)\n",
        "airport_line_graph.y = torch.from_numpy(np.vstack([edge_name_to_y[e] for e in G_line_graph.nodes])).to(torch.float32)\n",
        "print(airport_line_graph)\n",
        "\n",
        "split = RandomNodeSplit(num_val=0.1, num_test=0.4)\n",
        "data = split(airport_line_graph)\n",
        "data = data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoovTnV84n0G"
      },
      "outputs": [],
      "source": [
        "edge_array = np.array(list(dict(G_line_graph.nodes).keys()))\n",
        "edge_index_train = edge_array[data.train_mask.detach().numpy()]\n",
        "edge_index_val = edge_array[data.val_mask.detach().numpy()]\n",
        "edge_index_calib_test = edge_array[data.test_mask.detach().numpy()]\n",
        "\n",
        "edge_weight_train = torch.Tensor(np.stack([edge_name_to_y[tuple(edge)] for edge in edge_index_train])).to(device)\n",
        "edge_weight_val = torch.Tensor(np.stack([edge_name_to_y[tuple(edge)] for edge in edge_index_val])).to(device)\n",
        "edge_weight_calib_test = torch.Tensor(np.stack([edge_name_to_y[tuple(edge)] for edge in edge_index_calib_test])).to(device)\n",
        "\n",
        "edge_index_train = torch.LongTensor(edge_index_train).T.to(device)\n",
        "edge_index_val = torch.LongTensor(edge_index_val).T.to(device)\n",
        "edge_index_calib_test = torch.LongTensor(edge_index_calib_test).T.to(device)\n",
        "edge_tensor = torch.LongTensor(edge_array).T.to(device)\n",
        "edge_tensor2 = edge_tensor\n",
        "edge_index_val2=edge_index_val\n",
        "edge_index_train2=edge_index_train\n",
        "edge_index_calib_test2=edge_index_calib_test\n",
        "\n",
        "edge_weight_train2=edge_weight_train\n",
        "edge_weight_val2=edge_weight_val\n",
        "edge_weight_calib_test2=edge_weight_calib_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TM07KyJCzFWZ"
      },
      "outputs": [],
      "source": [
        "edge_weight_gae_training = [edge_name_to_y[tuple(edge)] if train else 1.0 for edge, train in zip(edge_array, data.train_mask.detach().numpy())]\n",
        "edge_weight_gae_training = torch.Tensor(edge_weight_gae_training).to(device) # torch.ones(edge_array.shape[0]).to(device)\n",
        "edge_weight_gae_training2 = edge_weight_gae_training\n",
        "\n",
        "# w_min, w_max = edge_weight_gae_training.min(), edge_weight_gae_training.max()\n",
        "# edge_weight_gae_training = (edge_weight_gae_training - w_min) / (w_max - w_min)# * 0.5 + 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XMOyPzuysWS"
      },
      "outputs": [],
      "source": [
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, gconv=SAGEConv):\n",
        "        super().__init__()\n",
        "        self.conv1 = gconv(in_channels, hidden_channels)\n",
        "        self.conv2 = gconv(hidden_channels, out_channels)\n",
        "        self.gconv = gconv\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        if self.gconv not in [GCNConv, GraphConv]:\n",
        "            edge_weight = None\n",
        "        if edge_weight is not None:\n",
        "            edge_weight = (edge_weight).sigmoid()\n",
        "        x = self.conv1(x, edge_index, edge_weight)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index, edge_weight)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiWFC1WZUNyw"
      },
      "outputs": [],
      "source": [
        "class DirectedGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, gconv=SAGEConv):\n",
        "        super().__init__()\n",
        "        self.layers = [in_channels, hidden_channels, out_channels]\n",
        "        self.num_layers = len(self.layers) - 1\n",
        "        self.source = torch.nn.ModuleList()\n",
        "        self.target = torch.nn.ModuleList()\n",
        "        self.gconv = gconv\n",
        "        for n_in, n_out in zip(self.layers[:-1], self.layers[1:]):\n",
        "            self.source.append(gconv(n_in, n_out))\n",
        "            self.target.append(gconv(n_in, n_out))\n",
        "\n",
        "    def forward(self, s, t, edge_index, edge_weight=None):\n",
        "        if self.gconv not in [GCNConv, GraphConv]:\n",
        "            edge_weight = None\n",
        "        if edge_weight is not None:\n",
        "            edge_weight = (edge_weight).sigmoid()\n",
        "        for layer_id, (layer_s, layer_t) in enumerate(zip(self.source, self.target)):\n",
        "            s_new = layer_s(t, edge_index, edge_weight)\n",
        "            t_new = layer_t(s, torch.flip(edge_index, [0]), edge_weight)\n",
        "            if layer_id < self.num_layers - 1:\n",
        "                s_new = s_new.relu()\n",
        "                t_new = t_new.relu()\n",
        "                s_new = F.dropout(s_new, p=0.5, training=self.training)\n",
        "                t_new = F.dropout(t_new, p=0.5, training=self.training)\n",
        "            s = s_new\n",
        "            t = t_new\n",
        "\n",
        "        return s, t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "946smt5pnGUC"
      },
      "outputs": [],
      "source": [
        "def cqr2_new(cal_labels2, cal_labels, cal_lower, cal_upper, val_labels2, val_labels, val_lower, val_upper, n, alpha):\n",
        "    cal_scores = np.maximum((cal_labels-cal_upper)/ np.abs(cal_labels2), (cal_lower-cal_labels) / np.abs(cal_labels2))\n",
        "    qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n, method='higher')\n",
        "    prediction_sets = [val_lower - qhat * np.abs(val_labels2), val_upper + qhat*np.abs(val_labels2)]\n",
        "    cov = ((val_labels >= prediction_sets[0]) & (val_labels <= prediction_sets[1])).mean()\n",
        "    # eff = np.mean(val_upper + qhat - (val_lower - qhat))\n",
        "    #print(2* qhat * np.abs(val_labels2))\n",
        "    eff = np.mean(prediction_sets[1] - prediction_sets[0])\n",
        "    return prediction_sets, cov, eff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQhH87K40Ela"
      },
      "outputs": [],
      "source": [
        "def cqr_new(cal_labels, cal_lower, cal_upper, val_labels, val_lower, val_upper, n, alpha):\n",
        "    cal_scores = np.maximum(cal_labels-cal_upper, cal_lower-cal_labels)\n",
        "    cal_scores = cal_scores / np.abs(cal_upper - cal_lower)\n",
        "    qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n, method='higher')\n",
        "    prediction_sets = [val_lower - qhat * np.abs(val_upper - val_lower), val_upper + qhat * np.abs(val_upper - val_lower)]\n",
        "    cov = ((val_labels >= prediction_sets[0]) & (val_labels <= prediction_sets[1])).mean()\n",
        "    eff = np.mean(prediction_sets[1] - prediction_sets[0])\n",
        "    return prediction_sets, cov, eff\n",
        "\n",
        "def cqr(cal_labels, cal_lower, cal_upper, val_labels, val_lower, val_upper, n, alpha):\n",
        "    cal_scores = np.maximum(cal_labels-cal_upper, cal_lower-cal_labels)\n",
        "    qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n, method='higher')\n",
        "    prediction_sets = [val_lower - qhat, val_upper + qhat]\n",
        "    cov = ((val_labels >= prediction_sets[0]) & (val_labels <= prediction_sets[1])).mean()\n",
        "    eff = np.mean(val_upper + qhat - (val_lower - qhat))\n",
        "    return prediction_sets, cov, eff\n",
        "\n",
        "def qr(cal_labels, cal_lower, cal_upper, val_labels, val_lower, val_upper, n, alpha):\n",
        "    prediction_sets = [val_lower, val_upper]\n",
        "    cov = ((val_labels >= prediction_sets[0]) & (val_labels <= prediction_sets[1])).mean()\n",
        "    eff = np.mean(val_upper - val_lower)\n",
        "    return prediction_sets, cov, eff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLpxh3kxikzD"
      },
      "outputs": [],
      "source": [
        "def worst_slice_coverage(x, edge_index_calib_test, idx, val_labels, prediction_sets):\n",
        "    if torch.is_tensor(x):\n",
        "        x = x.detach().numpy()\n",
        "    if torch.is_tensor(edge_index_calib_test):\n",
        "        edge_index_calib_test = edge_index_calib_test.detach().numpy()\n",
        "    xtest = np.hstack([x[edge_index_calib_test[0, ~idx]], x[edge_index_calib_test[1, ~idx]]])\n",
        "    ntest = xtest.shape[0]\n",
        "    nfeat = xtest.shape[1]\n",
        "    xtest_test = xtest[:ntest//4]\n",
        "    unitvec = np.random.randn(nfeat, 1000)\n",
        "    unitvec = unitvec / np.sqrt((unitvec**2).sum(axis=0))\n",
        "    # ab_range = np.quantile((xtest_test @ unitvec).flatten(), np.linspace(0, 1, 11))\n",
        "    values = (xtest_test @ unitvec).flatten()\n",
        "    ab_range = np.linspace(values.min(), values.max(), 10)\n",
        "\n",
        "    ws_cov_min = None\n",
        "    for delta in np.linspace(0.1, 0.5, 5):\n",
        "        ws_cov = 1\n",
        "        ws_a = None\n",
        "        ws_b = None\n",
        "        ws_vec = None\n",
        "        for vec in unitvec.T:\n",
        "            value_vec = xtest_test @ vec.reshape(-1, 1)\n",
        "            for a, b in zip(ab_range[:-1], ab_range[1:]):\n",
        "                contained = np.bitwise_and(value_vec > a, value_vec < b).flatten()\n",
        "                if contained.mean() > delta:\n",
        "                    conditional_cov = ((val_labels[:ntest//4][contained] >= prediction_sets[0][:ntest//4][contained]) & (val_labels[:ntest//4][contained] <= prediction_sets[1][:ntest//4][contained])).mean()\n",
        "                    if conditional_cov < ws_cov:\n",
        "                        #print(f\"Worst-Slice coverage = {conditional_cov:.4f}\")\n",
        "                        ws_cov = conditional_cov\n",
        "                        ws_a = a\n",
        "                        ws_b = b\n",
        "                        ws_vec = vec\n",
        "        if ws_vec is None:\n",
        "            return None\n",
        "        xtest_true = xtest[ntest//4:]\n",
        "        value_vec = xtest_true @ ws_vec.reshape(-1, 1)\n",
        "        contained = np.bitwise_and(value_vec > ws_a, value_vec < ws_b).flatten()\n",
        "        ws_cov_true = ((val_labels[ntest//4:][contained] >= prediction_sets[0][ntest//4:][contained]) & (val_labels[ntest//4:][contained] <= prediction_sets[1][ntest//4:][contained])).mean()\n",
        "        if ws_cov_min is not None and ws_cov_true < ws_cov_min:\n",
        "            ws_cov_min = ws_cov_true\n",
        "        elif ws_cov_min is None and ~np.isnan(ws_cov_true):\n",
        "            ws_cov_min = ws_cov_true\n",
        "    return ws_cov_min\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lngOwUWC-iq"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5001\n",
        "ALPHA = 0.05\n",
        "LR = 0.01\n",
        "WD = 5e-4\n",
        "HIDDEN = 8\n",
        "OUT = 2\n",
        "\n",
        "######################\n",
        "SCORE = 'cqr2_new'\n",
        "GNNCONV = GATConv\n",
        "# CP_or_CQR\n",
        "# Dataset\n",
        "# DiGAE_or_GAE_or_LGNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQCnq_-Rn5Ur"
      },
      "outputs": [],
      "source": [
        "def train_linegraph(alpha=ALPHA, val=False):\n",
        "    if val:\n",
        "        model.eval()\n",
        "    else:\n",
        "        model.train()\n",
        "    mask = data.val_mask if val else data.train_mask\n",
        "    out = model(data.x, data.edge_index)\n",
        "    out1=out\n",
        "    label = data.y[mask]\n",
        "    mse_loss = F.mse_loss(out[:, 0][mask], data.y[mask])\n",
        "    low_bound = alpha / 2\n",
        "    upp_bound = 1 - alpha / 2\n",
        "    lower = out[:, 1][mask].reshape(-1,1)\n",
        "    upper = out[:, 2][mask].reshape(-1,1)\n",
        "    low_loss = torch.mean(torch.max((low_bound - 1) * (label - lower), low_bound * (label - lower)))\n",
        "    upp_loss = torch.mean(torch.max((upp_bound - 1) * (label - upper), upp_bound * (label - upper)))\n",
        "    loss = mse_loss/1.6 + low_loss/0.1 + upp_loss/0.05\n",
        "\n",
        "    if val:\n",
        "        model2.train()\n",
        "    else:\n",
        "        model2.eval()\n",
        "    mask = data.val_mask if val else data.train_mask\n",
        "    out2 = model2(data.x, data.edge_index)\n",
        "    label2 = data.y[mask]-out[mask] #   new labels: X-X_hat\n",
        "    label3 = upper-lower\n",
        "\n",
        "    mse_loss2 = F.mse_loss(out2[:,0][mask].reshape(-1,1), label2)\n",
        "    mse_loss3 = F.mse_loss(out2[:,1][mask].reshape(-1,1), label3)\n",
        "    loss2 = mse_loss2/11.3  #+ mse_loss3/1\n",
        "    print('mse_loss of model2')\n",
        "    print(mse_loss2)\n",
        "    print('mse_loss of model2')\n",
        "    print(mse_loss3)\n",
        "\n",
        "    if val:\n",
        "        optimizer2.zero_grad()\n",
        "        loss2.backward()\n",
        "        optimizer2.step()\n",
        "    if not val:\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return float(loss),float(loss2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LZCIPsUC2j-"
      },
      "source": [
        "# DiGAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heFgMAQMVDJo"
      },
      "outputs": [],
      "source": [
        "def train_gae_directed(x2, x,edge_index_train2, edge_index_train,edge_weight2, edge_weight, alpha=ALPHA, val=False, edge_index_val=None, sigmoid=False):\n",
        "    if val:\n",
        "        model.eval()\n",
        "    else:\n",
        "        model.train()\n",
        "    Z_source, Z_target = model(x, x, edge_tensor, edge_weight_gae_training)\n",
        "    out_dim = Z_source.shape[-1] // 3\n",
        "    z_mid_source = Z_source[:, :out_dim]; z_lower_source = Z_source[:, out_dim:2*out_dim]; z_upper_source = Z_source[:, 2*out_dim:]\n",
        "    z_mid_target = Z_target[:, :out_dim]; z_lower_target = Z_target[:, out_dim:2*out_dim]; z_upper_target = Z_target[:, 2*out_dim:]\n",
        "    if val:\n",
        "        out = model.decoder(z_mid_source, z_mid_target, edge_index_val, sigmoid=sigmoid)\n",
        "        lower = model.decoder(z_lower_source, z_lower_target, edge_index_val, sigmoid=sigmoid)\n",
        "        upper = model.decoder(z_upper_source, z_upper_target, edge_index_val, sigmoid=sigmoid)\n",
        "    else:\n",
        "        out = model.decoder(z_mid_source, z_mid_target, edge_index_train, sigmoid=sigmoid)\n",
        "        lower = model.decoder(z_lower_source, z_lower_target, edge_index_train, sigmoid=sigmoid)\n",
        "        upper = model.decoder(z_upper_source, z_upper_target, edge_index_train, sigmoid=sigmoid)\n",
        "\n",
        "    label = edge_weight\n",
        "    mse_loss = F.mse_loss(out, label)\n",
        "    label2 = out - label\n",
        "    low_bound = alpha / 2; upp_bound = 1 - alpha / 2\n",
        "    low_loss = torch.mean(torch.max((low_bound - 1) * (label - lower), low_bound * (label - lower)))\n",
        "    upp_loss = torch.mean(torch.max((upp_bound - 1) * (label - upper), upp_bound * (label - upper)))\n",
        "    loss = low_loss/1.25 + upp_loss/2.5 + mse_loss/50\n",
        "\n",
        "    if val:\n",
        "        model2.train()\n",
        "    else:\n",
        "        model2.eval()\n",
        "    #print('1')\n",
        "\n",
        "    Z_source2, Z_target2 = model2(x2, x2, edge_tensor2, edge_weight_gae_training2)\n",
        "    out_dim2 = Z_source2.shape[-1] // 3\n",
        "    z_mid_source2 = Z_source2[:, :out_dim2]; z_lower_source2 = Z_source2[:, out_dim2:2*out_dim2]; z_upper_source2 = Z_source2[:, 2*out_dim2:]\n",
        "    z_mid_target2 = Z_target2[:, :out_dim2]; z_lower_target2 = Z_target2[:, out_dim2:2*out_dim2]; z_upper_target2 = Z_target2[:, 2*out_dim2:]\n",
        "    #print('2')\n",
        "    if not val:\n",
        "        out2 = model2.decoder(z_mid_source2, z_mid_target2, edge_index_train, sigmoid=sigmoid)\n",
        "        #lower2 = model2.decoder(z_lower_source2, z_lower_target2, edge_index_train, sigmoid=sigmoid)\n",
        "        #upper2 = model2.decoder(z_upper_source2, z_upper_target2, edge_index_train, sigmoid=sigmoid)\n",
        "    else:\n",
        "        out2 = model2.decoder(z_mid_source2, z_mid_target2, edge_index_val, sigmoid=sigmoid)\n",
        "        #lower2 = model2.decoder(z_lower_source2, z_lower_target2, edge_index_val, sigmoid=sigmoid)\n",
        "        #upper2 = model2.decoder(z_upper_source2, z_upper_target2, edge_index_val, sigmoid=sigmoid)\n",
        "    #print('3')\n",
        "    mse_loss2 = F.mse_loss(out2, label2)\n",
        "    loss2 = mse_loss2/50  #+ mse_loss3/1\n",
        "\n",
        "    #print('mse_loss of model2')\n",
        "    #print(mse_loss2)\n",
        "    if val:\n",
        "        optimizer2.zero_grad()\n",
        "        loss2.backward()\n",
        "        optimizer2.step()\n",
        "    if not val:\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return float(loss), float(loss2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0aR8Ca_Us0b"
      },
      "outputs": [],
      "source": [
        "def run_conformal_regression_gae(labels2,labels, lower, upper, alpha=ALPHA, return_prediction_sets=False, return_conditional_coverage=False, score='cqr', x=None, edge_index_calib_test=None):\n",
        "    num_runs = 100\n",
        "    if torch.is_tensor(labels):\n",
        "        labels = labels.detach().numpy()\n",
        "    if torch.is_tensor(upper):\n",
        "        upper = upper.detach().numpy()\n",
        "    if torch.is_tensor(lower):\n",
        "        lower = lower.detach().numpy()\n",
        "\n",
        "    n_test_calib = labels.shape[0]\n",
        "    n_calib = n_test_calib // 2\n",
        "    idx = np.array([1] * n_calib + [0] * (n_test_calib-n_calib)) > 0\n",
        "\n",
        "    cov_all = []\n",
        "    eff_all = []\n",
        "    if return_conditional_coverage:\n",
        "        ws_cov_all = []\n",
        "    if return_prediction_sets:\n",
        "        pred_set_all = []\n",
        "        val_labels_all = []\n",
        "        idx_all = []\n",
        "    for k in range(num_runs):\n",
        "        np.random.seed(k)\n",
        "        np.random.shuffle(idx)\n",
        "        if return_prediction_sets:\n",
        "            idx_all.append(idx)\n",
        "        cal_labels, val_labels = labels[idx], labels[~idx]\n",
        "        cal_labels2, val_labels2 = labels2[idx], labels2[~idx]\n",
        "        cal_upper, val_upper = upper[idx], upper[~idx]\n",
        "        cal_lower, val_lower = lower[idx], lower[~idx]\n",
        "        if score == 'cqr':\n",
        "            prediction_sets, cov, eff = cqr(cal_labels, cal_lower, cal_upper, val_labels, val_lower, val_upper, n_test_calib, alpha)\n",
        "        elif score == 'qr':\n",
        "            prediction_sets, cov, eff = qr(cal_labels, cal_lower, cal_upper, val_labels, val_lower, val_upper, n_test_calib, alpha)\n",
        "        elif score == 'cqr_new':\n",
        "            prediction_sets, cov, eff = cqr_new(cal_labels, cal_lower, cal_upper, val_labels, val_lower, val_upper, n_test_calib, alpha)\n",
        "        elif score == 'cqr2_new':\n",
        "            prediction_sets, cov, eff = cqr2_new(cal_labels2, cal_labels, cal_lower, cal_upper,val_labels2, val_labels, val_lower, val_upper, n_test_calib, alpha)\n",
        "\n",
        "        if return_conditional_coverage:\n",
        "            ws_cov = worst_slice_coverage(x, edge_index_calib_test, idx, val_labels, prediction_sets)\n",
        "            if ws_cov is not None:\n",
        "                ws_cov_all.append(ws_cov)\n",
        "        cov_all.append(cov)\n",
        "        eff_all.append(eff)\n",
        "        if return_prediction_sets:\n",
        "            pred_set_all.append(prediction_sets)\n",
        "            val_labels_all.append(val_labels)\n",
        "\n",
        "    if return_prediction_sets:\n",
        "        if return_conditional_coverage:\n",
        "            return cov_all, eff_all, ws_cov_all, pred_set_all, val_labels_all, idx_all\n",
        "        return cov_all, eff_all, pred_set_all, val_labels_all, idx_all\n",
        "    else:\n",
        "        return np.mean(cov_all), np.mean(eff_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU1XAqULXyPQ"
      },
      "outputs": [],
      "source": [
        "def test_gae_directed(best_model, x, train_edge_index, calib_test_edge_index, calib_test_edge_weight, alpha=ALPHA, return_prediction_sets=False, score='cqr', conditional=True, sigmoid=False):\n",
        "    best_model = best_model.cpu()\n",
        "    best_model.eval()\n",
        "    Z_source, Z_target = best_model(x.cpu(), x.cpu(), edge_tensor.cpu(), edge_weight_gae_training.cpu())\n",
        "    out_dim = Z_source.shape[-1] // 3\n",
        "    z_mid_source = Z_source[:, :out_dim]; z_lower_source = Z_source[:, out_dim:2*out_dim]; z_upper_source = Z_source[:, 2*out_dim:]\n",
        "    z_mid_target = Z_target[:, :out_dim]; z_lower_target = Z_target[:, out_dim:2*out_dim]; z_upper_target = Z_target[:, 2*out_dim:]\n",
        "\n",
        "    out = best_model.decoder(z_mid_source, z_mid_target, calib_test_edge_index.cpu(), sigmoid=sigmoid)\n",
        "    lower = best_model.decoder(z_lower_source, z_lower_target, calib_test_edge_index.cpu(), sigmoid=sigmoid)\n",
        "    upper = best_model.decoder(z_upper_source, z_upper_target, calib_test_edge_index.cpu(), sigmoid=sigmoid)\n",
        "    label2 = calib_test_edge_weight.cpu().detach().numpy() - out.cpu().detach().numpy()\n",
        "    if conditional:\n",
        "        return run_conformal_regression_gae(label2, calib_test_edge_weight.cpu(), lower, upper, alpha, return_prediction_sets=return_prediction_sets, return_conditional_coverage=True, x=x, edge_index_calib_test=calib_test_edge_index)\n",
        "\n",
        "    return run_conformal_regression_gae(label2, calib_test_edge_weight.cpu(), lower, upper, alpha, return_prediction_sets=return_prediction_sets, score=score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7Abh8vrUwuR"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    encoder = DirectedGNN(in_channels=airport.x.shape[-1], hidden_channels=HIDDEN, out_channels=3*OUT, gconv=GNNCONV)\n",
        "    encoder2 = DirectedGNN(in_channels=airport.x.shape[-1], hidden_channels=HIDDEN, out_channels=1*OUT, gconv=GNNCONV)\n",
        "\n",
        "    decoder = DirectedInnerProductDecoder()\n",
        "    decoder2 = DirectedInnerProductDecoder()\n",
        "\n",
        "    model = GAE(encoder, decoder).to(device)\n",
        "    model2 =GAE(encoder2, decoder2).to(device)\n",
        "    x = airport.x.to(device)\n",
        "\n",
        "    edge_index_train2 = edge_index_train\n",
        "    edge_weight_train2 = edge_weight_train\n",
        "    edge_index_train2 = edge_index_train\n",
        "    edge_weight_train2 =edge_weight_train\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "    optimizer2 = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    val_loss = float('inf')\n",
        "    best_model = None\n",
        "    use_sigmoid = False\n",
        "    for epoch in range(1, 6*EPOCHS):\n",
        "        if epoch%4 ==0:\n",
        "            val1 = True\n",
        "            val_loss,val_loss2 = train_gae_directed(x,x,edge_index_val2, edge_index_val,edge_weight_val2, edge_weight_val, val=val1, edge_index_val=edge_index_val, sigmoid=use_sigmoid)\n",
        "\n",
        "        else:\n",
        "            val1=False\n",
        "            val_lossn, val_loss2n = train_gae_directed(x, x, edge_index_train2, edge_index_train,edge_weight_train2, edge_weight_train,val=val1, sigmoid=use_sigmoid)\n",
        "\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "        #print(f'Epoch: {epoch:03d}, Best validation loss: {val_loss:.4f}')\n",
        "    _, cov_all, eff_all, pred_set_all, val_labels_all, idx_all = test_gae_directed(best_model.cpu(), x.cpu(), edge_index_train, edge_index_calib_test, edge_weight_calib_test, return_prediction_sets=True, score=SCORE, sigmoid=use_sigmoid, conditional=True)\n",
        "    print(f\"{np.mean(cov_all):.4f}+/-{np.std(cov_all):.4f}, {np.mean(eff_all):.4f}+/-{np.std(eff_all):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbjrkcnydR2-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0_jLl-ixzI1"
      },
      "outputs": [],
      "source": [
        "#cov_all, eff_all, ws_cov_all, pred_set_all, val_labels_all, idx_all = test_gae_directed(best_model, x, edge_index_train, edge_index_calib_test, edge_weight_calib_test, return_prediction_sets=True, score='cqr_new', sigmoid=use_sigmoid, conditional=True)\n",
        "cov_all, eff_all, pred_set_all, val_labels_all, idx_all = test_gae_directed(best_model.cpu(), x.cpu(), edge_index_train, edge_index_calib_test, edge_weight_calib_test, return_prediction_sets=True, score=SCORE, sigmoid=use_sigmoid, conditional=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2ZZP57OUrMJ",
        "outputId": "df268458-fa4e-4962-a3ad-a5807d9c84ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9504+/-0.0167, 3.7640+/-0.0497\n"
          ]
        }
      ],
      "source": [
        "# print(f\"{np.mean(cov_all):.4f}+/-{np.std(cov_all):.4f}, {np.mean(eff_all):.4f}+/-{np.std(eff_all):.4f}, {np.mean(ws_cov_all):.4f}+/-{np.std(ws_cov_all):.4f}\")\n",
        "print(f\"{np.mean(cov_all):.4f}+/-{np.std(cov_all):.4f}, {np.mean(eff_all):.4f}+/-{np.std(eff_all):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6O0EZxHnDgX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Gg1IJwbOsb"
      },
      "source": [
        "# GAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpEbDsH6bQaz"
      },
      "outputs": [],
      "source": [
        "def train_gae(x, edge_index_train, edge_weight, alpha=ALPHA, val=False, edge_index_val=None, sigmoid=False):\n",
        "    if val:\n",
        "        model.eval()\n",
        "    else:\n",
        "        model.train()\n",
        "    Z = model(x, edge_tensor, edge_weight_gae_training)\n",
        "    out_dim = Z.shape[-1] // 3\n",
        "    z_mid = Z[:, :out_dim]; z_lower = Z[:, out_dim:2*out_dim]; z_upper = Z[:, 2*out_dim:]\n",
        "    if val:\n",
        "        out = model.decoder(z_mid, edge_index_val, sigmoid=sigmoid)\n",
        "        lower = model.decoder(z_lower, edge_index_val, sigmoid=sigmoid)\n",
        "        upper = model.decoder(z_upper, edge_index_val, sigmoid=sigmoid)\n",
        "    else:\n",
        "        out = model.decoder(z_mid, edge_index_train, sigmoid=sigmoid)\n",
        "        lower = model.decoder(z_lower, edge_index_train, sigmoid=sigmoid)\n",
        "        upper = model.decoder(z_upper, edge_index_train, sigmoid=sigmoid)\n",
        "\n",
        "    label = edge_weight\n",
        "    mse_loss = F.mse_loss(out, label)\n",
        "    low_bound = alpha / 2; upp_bound = 1 - alpha / 2\n",
        "    low_loss = torch.mean(torch.max((low_bound - 1) * (label - lower), low_bound * (label - lower)))\n",
        "    upp_loss = torch.mean(torch.max((upp_bound - 1) * (label - upper), upp_bound * (label - upper)))\n",
        "    loss = low_loss + upp_loss # mse_loss +\n",
        "\n",
        "    if not val:\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return float(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6thXA1-AWt4"
      },
      "outputs": [],
      "source": [
        "def run_conformal_regression_gae2(labels2,labels, lower, upper, alpha=ALPHA, return_prediction_sets=False, return_conditional_coverage=False, score='cqr', x=None, edge_index_calib_test=None):\n",
        "    num_runs = 100\n",
        "    if torch.is_tensor(labels):\n",
        "        labels = labels.detach().numpy()\n",
        "    if torch.is_tensor(upper):\n",
        "        upper = upper.detach().numpy()\n",
        "    if torch.is_tensor(lower):\n",
        "        lower = lower.detach().numpy()\n",
        "\n",
        "    n_test_calib = labels.shape[0]\n",
        "    n_calib = n_test_calib // 2\n",
        "    idx = np.array([1] * n_calib + [0] * (n_test_calib-n_calib)) > 0\n",
        "\n",
        "    cov_all = []\n",
        "    eff_all = []\n",
        "    if return_conditional_coverage:\n",
        "        ws_cov_all = []\n",
        "    if return_prediction_sets:\n",
        "        pred_set_all = []\n",
        "        val_labels_all = []\n",
        "        idx_all = []\n",
        "    for k in range(num_runs):\n",
        "        np.random.seed(k)\n",
        "        np.random.shuffle(idx)\n",
        "        if return_prediction_sets:\n",
        "            idx_all.append(idx)\n",
        "        cal_labels, val_labels = labels[idx], labels[~idx]\n",
        "        cal_labels2, val_labels2 = labels2[idx], labels2[~idx]\n",
        "        cal_upper, val_upper = upper[idx], upper[~idx]\n",
        "        cal_lower, val_lower = lower[idx], lower[~idx]\n",
        "        if score == 'cqr':\n",
        "            prediction_sets, cov, eff = cqr(cal_labels, cal_lower, cal_upper, val_labels, val_lower, val_upper, n_test_calib, alpha)\n",
        "        elif score == 'qr':\n",
        "            prediction_sets, cov, eff = qr(cal_labels, cal_lower, cal_upper, val_labels, val_lower, val_upper, n_test_calib, alpha)\n",
        "        elif score == 'cqr_new':\n",
        "            prediction_sets, cov, eff = cqr_new(cal_labels, cal_lower, cal_upper, val_labels, val_lower, val_upper, n_test_calib, alpha)\n",
        "        elif score == 'cqr2_new':\n",
        "            prediction_sets, cov, eff = cqr2_new(cal_labels2, cal_labels, cal_lower, cal_upper,val_labels2, val_labels, val_lower, val_upper, n_test_calib, alpha)\n",
        "\n",
        "        if return_conditional_coverage:\n",
        "            ws_cov = worst_slice_coverage(x, edge_index_calib_test, idx, val_labels, prediction_sets)\n",
        "            if ws_cov is not None:\n",
        "                ws_cov_all.append(ws_cov)\n",
        "        cov_all.append(cov)\n",
        "        eff_all.append(eff)\n",
        "        if return_prediction_sets:\n",
        "            pred_set_all.append(prediction_sets)\n",
        "            val_labels_all.append(val_labels)\n",
        "\n",
        "    if return_prediction_sets:\n",
        "        if return_conditional_coverage:\n",
        "            return cov_all, eff_all, ws_cov_all, pred_set_all, val_labels_all, idx_all\n",
        "        return cov_all, eff_all, pred_set_all, val_labels_all, idx_all\n",
        "    else:\n",
        "        return np.mean(cov_all), np.mean(eff_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3G8vnkWdoS2"
      },
      "outputs": [],
      "source": [
        "def train_gae2o(x2, x, edge_index_train2, edge_index_train, edge_weight2, edge_weight, alpha=ALPHA, val=False, edge_index_val=None, sigmoid=False):\n",
        "    if val:\n",
        "        model.eval()\n",
        "    else:\n",
        "        model.train()\n",
        "    Z = model(x, edge_tensor, edge_weight_gae_training)\n",
        "    out_dim = Z.shape[-1] // 3\n",
        "    z_mid = Z[:, :out_dim]; z_lower = Z[:, out_dim:2*out_dim]; z_upper = Z[:, 2*out_dim:]\n",
        "    if val:\n",
        "        out = model.decoder(z_mid, edge_index_val, sigmoid=sigmoid)\n",
        "        lower = model.decoder(z_lower, edge_index_val, sigmoid=sigmoid)\n",
        "        upper = model.decoder(z_upper, edge_index_val, sigmoid=sigmoid)\n",
        "    else:\n",
        "        out = model.decoder(z_mid, edge_index_train, sigmoid=sigmoid)\n",
        "        lower = model.decoder(z_lower, edge_index_train, sigmoid=sigmoid)\n",
        "        upper = model.decoder(z_upper, edge_index_train, sigmoid=sigmoid)\n",
        "\n",
        "    label = edge_weight\n",
        "    mse_loss = F.mse_loss(out, label)\n",
        "    label2 = out - label\n",
        "    low_bound = alpha / 2; upp_bound = 1 - alpha / 2\n",
        "    low_loss = torch.mean(torch.max((low_bound - 1) * (label - lower), low_bound * (label - lower)))\n",
        "    upp_loss = torch.mean(torch.max((upp_bound - 1) * (label - upper), upp_bound * (label - upper)))\n",
        "    loss = low_loss + upp_loss # mse_loss +\n",
        "\n",
        "\n",
        "    if val:\n",
        "        model2.train()\n",
        "    else:\n",
        "        model2.eval()\n",
        "\n",
        "    Z2 = model2(x2, edge_tensor2, edge_weight_gae_training2)\n",
        "    out_dim2 = Z2.shape[-1] // 3\n",
        "    z_mid2 = Z2[:, :out_dim2]; z_lower2 = Z2[:, out_dim2:2*out_dim2]; z_upper2 = Z2[:, 2*out_dim2:]\n",
        "    if not val:\n",
        "        out2 = model2.decoder(z_mid2, edge_index_val2, sigmoid=sigmoid)\n",
        "        #lower = model.decoder(z_lower, edge_index_val, sigmoid=sigmoid)\n",
        "        #upper = model.decoder(z_upper, edge_index_val, sigmoid=sigmoid)\n",
        "    else:\n",
        "        out2 = model2.decoder(z_mid2, edge_index_train2, sigmoid=sigmoid)\n",
        "        #lower = model.decoder(z_lower, edge_index_train, sigmoid=sigmoid)\n",
        "        #upper = model.decoder(z_upper, edge_index_train, sigmoid=sigmoid)\n",
        "\n",
        "    #mse_loss2 = F.mse_loss(out2, label2)\n",
        "\n",
        "    #print(label2)\n",
        "    #print('outttttttttttttttttttttt2')\n",
        "    #print(out2)\n",
        "    mse_loss2 = F.mse_loss(label2[0:215], out2)\n",
        "\n",
        "    loss2 =  mse_loss2\n",
        "\n",
        "\n",
        "    if not val:\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if val:\n",
        "        optimizer2.zero_grad()\n",
        "        loss2.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "    return float(loss), float(loss2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TtFU4Ft12-s"
      },
      "outputs": [],
      "source": [
        "def train_gae2(x2, x, edge_index_train2, edge_index_train, edge_weight2, edge_weight, alpha=ALPHA, val=False, edge_index_val=None, sigmoid=False):\n",
        "\n",
        "\n",
        "    if val:\n",
        "        model.eval()\n",
        "    else:\n",
        "        model.train()\n",
        "    Z_source = model( x, edge_tensor, edge_weight_gae_training)\n",
        "    out_dim = Z_source.shape[-1] // 3\n",
        "    z_mid_source = Z_source[:, :out_dim]; z_lower_source = Z_source[:, out_dim:2*out_dim]; z_upper_source = Z_source[:, 2*out_dim:]\n",
        "    if val:\n",
        "        out = model.decoder(z_mid_source, edge_index_val, sigmoid=sigmoid)\n",
        "        lower = model.decoder(z_lower_source, edge_index_val, sigmoid=sigmoid)\n",
        "        upper = model.decoder(z_upper_source, edge_index_val, sigmoid=sigmoid)\n",
        "    else:\n",
        "        out = model.decoder(z_mid_source, edge_index_train, sigmoid=sigmoid)\n",
        "        lower = model.decoder(z_lower_source, edge_index_train, sigmoid=sigmoid)\n",
        "        upper = model.decoder(z_upper_source, edge_index_train, sigmoid=sigmoid)\n",
        "\n",
        "    label = edge_weight\n",
        "    mse_loss = F.mse_loss(out, label)\n",
        "    label2 = out - label\n",
        "    low_bound = alpha / 2; upp_bound = 1 - alpha / 2\n",
        "    low_loss = torch.mean(torch.max((low_bound - 1) * (label - lower), low_bound * (label - lower)))\n",
        "    upp_loss = torch.mean(torch.max((upp_bound - 1) * (label - upper), upp_bound * (label - upper)))\n",
        "    loss = low_loss/1.25 + upp_loss/2.5 + mse_loss/50\n",
        "\n",
        "    #return float(loss)\n",
        "    #print('upper losss')\n",
        "    #print(upp_loss)\n",
        "    #print('lower loss')\n",
        "    #print(low_loss)\n",
        "    if val:\n",
        "        model2.train()\n",
        "    else:\n",
        "        model2.eval()\n",
        "    #print('1')\n",
        "\n",
        "    Z_source2 = model2( x2, edge_tensor2, edge_weight_gae_training2)\n",
        "    out_dim2 = Z_source2.shape[-1] // 3\n",
        "    z_mid_source2 = Z_source2[:, :out_dim2]; z_lower_source2 = Z_source2[:, out_dim2:2*out_dim2]; z_upper_source2 = Z_source2[:, 2*out_dim2:]\n",
        "    #print('2')\n",
        "    if not val:\n",
        "        out2 = model2.decoder(z_mid_source2, edge_index_train, sigmoid=sigmoid)\n",
        "        #lower2 = model2.decoder(z_lower_source2, z_lower_target2, edge_index_train, sigmoid=sigmoid)\n",
        "        #upper2 = model2.decoder(z_upper_source2, z_upper_target2, edge_index_train, sigmoid=sigmoid)\n",
        "    else:\n",
        "        out2 = model2.decoder(z_mid_source2, edge_index_val, sigmoid=sigmoid)\n",
        "        #lower2 = model2.decoder(z_lower_source2, z_lower_target2, edge_index_val, sigmoid=sigmoid)\n",
        "        #upper2 = model2.decoder(z_upper_source2, z_upper_target2, edge_index_val, sigmoid=sigmoid)\n",
        "    #print('3')\n",
        "    # 调整 out2 尺寸与 label2 相同\n",
        "    #out2_resized = F.interpolate(out2, size=(label2.size()), mode='bilinear', align_corners=False)\n",
        "\n",
        "    # 计算 MSE Loss\n",
        "    #mse_loss2 = F.mse_loss(out2_resized, label2)\n",
        "    mse_loss2 = F.mse_loss(out2, label2)\n",
        "    loss2 = mse_loss2/50  #+ mse_loss3/1\n",
        "\n",
        "    #print('mse_loss of model2')\n",
        "    #print(mse_loss2)\n",
        "    if val:\n",
        "        optimizer2.zero_grad()\n",
        "        loss2.backward()\n",
        "        optimizer2.step()\n",
        "    if not val:\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return float(loss), float(loss2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAWUzjISbDvR"
      },
      "outputs": [],
      "source": [
        "def test_gae(best_model, x, train_edge_index, calib_test_edge_index, calib_test_edge_weight, alpha=ALPHA, return_prediction_sets=False, score='cqr', conditional=True, sigmoid=False):\n",
        "    best_model = best_model.cpu()\n",
        "    best_model.eval()\n",
        "    Z = best_model(x.cpu(), edge_tensor.cpu(), edge_weight_gae_training.cpu())\n",
        "    out_dim = Z.shape[-1] // 3\n",
        "    z_mid = Z[:, :out_dim]; z_lower = Z[:, out_dim:2*out_dim]; z_upper = Z[:, 2*out_dim:]\n",
        "    out = model.decoder(z_mid, calib_test_edge_index.cpu(), sigmoid=sigmoid)\n",
        "    lower = model.decoder(z_lower, calib_test_edge_index.cpu(), sigmoid=sigmoid)\n",
        "    upper = model.decoder(z_upper, calib_test_edge_index.cpu(), sigmoid=sigmoid)\n",
        "    if conditional:\n",
        "        return run_conformal_regression_gae(calib_test_edge_weight.cpu(), lower, upper, alpha, return_prediction_sets=return_prediction_sets, return_conditional_coverage=True, x=x, edge_index_calib_test=calib_test_edge_index)\n",
        "\n",
        "    return run_conformal_regression_gae(calib_test_edge_weight.cpu(), lower, upper, alpha, return_prediction_sets=return_prediction_sets, score=score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woeYerVllqaA"
      },
      "outputs": [],
      "source": [
        "def test_gae2(best_model, x, train_edge_index, calib_test_edge_index, calib_test_edge_weight, alpha=ALPHA, return_prediction_sets=False, score='cqr', conditional=True, sigmoid=False):\n",
        "    best_model = best_model.cpu()\n",
        "    best_model.eval()\n",
        "    Z = best_model(x.cpu(), edge_tensor.cpu(), edge_weight_gae_training.cpu())\n",
        "    out_dim = Z.shape[-1] // 3\n",
        "    z_mid = Z[:, :out_dim]; z_lower = Z[:, out_dim:2*out_dim]; z_upper = Z[:, 2*out_dim:]\n",
        "    out = model.decoder(z_mid, calib_test_edge_index.cpu(), sigmoid=sigmoid)\n",
        "    lower = model.decoder(z_lower, calib_test_edge_index.cpu(), sigmoid=sigmoid)\n",
        "    upper = model.decoder(z_upper, calib_test_edge_index.cpu(), sigmoid=sigmoid)\n",
        "    label2 = calib_test_edge_weight.cpu().detach().numpy() - out.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "    if conditional:\n",
        "        return run_conformal_regression_gae2(label2,calib_test_edge_weight.cpu(), lower.detach().cpu().numpy(), upper.detach().cpu().numpy(), alpha, return_prediction_sets=return_prediction_sets, return_conditional_coverage=True, x=x, edge_index_calib_test=calib_test_edge_index)\n",
        "\n",
        "    return run_conformal_regression_gae2(label2, calib_test_edge_weight.cpu(), lower.detach().cpu().numpy(), upper.detach().cpu().numpy(), alpha, return_prediction_sets=return_prediction_sets, score=score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqvVA8qydmLC"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    encoder = GNN(in_channels=airport.x.shape[-1], hidden_channels=HIDDEN, out_channels=3*OUT, gconv=GNNCONV)\n",
        "    decoder = InnerProductDecoder()\n",
        "    model = GAE(encoder, decoder).to(device)\n",
        "\n",
        "    encoder2 = GNN(in_channels=airport.x.shape[-1], hidden_channels=HIDDEN, out_channels=3*OUT, gconv=GNNCONV)\n",
        "    decoder2 = InnerProductDecoder()\n",
        "    model2 = GAE(encoder2, decoder2).to(device)\n",
        "    #print(model2)\n",
        "    x = airport.x.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "    edge_index_train2 = edge_index_train\n",
        "    edge_weight_train2 = edge_weight_train\n",
        "    edge_index_train2 = edge_index_train\n",
        "    edge_weight_train2 =edge_weight_train\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    val_loss = float('inf')\n",
        "    best_model = None\n",
        "    use_sigmoid = False\n",
        "\n",
        "    for epoch in range(1, 6*EPOCHS):\n",
        "        if epoch%4 ==0:\n",
        "            val1 = True\n",
        "            val_loss,val_loss2 = train_gae2(x, x, edge_index_val2, edge_index_val, edge_weight_val2, edge_weight_val,val=val1, edge_index_val=edge_index_val,sigmoid=use_sigmoid)\n",
        "\n",
        "        else:\n",
        "            val1=False\n",
        "            val_lossn, val_loss2n = train_gae2(x, x,edge_index_train2, edge_index_train,edge_weight_train2, edge_weight_train,val=val1, sigmoid=use_sigmoid)\n",
        "\n",
        "        #loss = train_gae(x, edge_index_train, edge_weight_train, sigmoid=use_sigmoid)\n",
        "        #if epoch % 1 == 1:\n",
        "            #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        #val_loss = train_gae(x, edge_index_train, edge_weight_val, val=True, edge_index_val=edge_index_val, sigmoid=use_sigmoid)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "            #print(f'Epoch: {epoch:03d}, Best validation loss: {val_loss:.4f}')\n",
        "    _,cov_all, eff_all, pred_set_all, val_labels_all, idx_all = test_gae2(best_model, x, edge_index_train, edge_index_calib_test, edge_weight_calib_test, return_prediction_sets=True, score=SCORE, sigmoid=use_sigmoid, conditional=True)\n",
        "    print(f\"{np.mean(cov_all):.4f}+/-{np.std(cov_all):.4f}, {np.mean(eff_all):.4f}+/-{np.std(eff_all):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcT0mYjJdWMJ",
        "outputId": "b0c20c6f-f8cb-4e9b-efd5-fac67258f4cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9520+/-0.0159, 3.4561+/-0.0453\n"
          ]
        }
      ],
      "source": [
        "cov_all, eff_all, pred_set_all, val_labels_all, idx_all = test_gae2(best_model, x, edge_index_train, edge_index_calib_test, edge_weight_calib_test, return_prediction_sets=True, score=SCORE, sigmoid=use_sigmoid, conditional=False)\n",
        "print(f\"{np.mean(cov_all):.4f}+/-{np.std(cov_all):.4f}, {np.mean(eff_all):.4f}+/-{np.std(eff_all):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQrE8BoUDDGh"
      },
      "source": [
        "# Line Graph"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}